{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8700e36-fb5e-4267-bbaf-2d5813742569",
   "metadata": {
    "execution": {},
    "libroFormatter": "formatter-string"
   },
   "outputs": [],
   "source": [
    "import secretflow as sf\n",
    "from secretflow.security.aggregation import SPUAggregator, SecureAggregator\n",
    "from secretflow.ml.nn import FLModel\n",
    "from secretflow.utils.simulation.datasets import dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import boxcox1p\n",
    "from scipy.stats import boxcox_normmax\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from secretflow.utils.simulation.data.ndarray import create_ndarray\n",
    "\n",
    "\n",
    "# Check the version of your SecretFlow\n",
    "print(\"The version of SecretFlow: {}\".format(sf.__version__))\n",
    "\n",
    "# In case you have a running secretflow runtime already.\n",
    "sf.shutdown()\n",
    "\n",
    "sf.init([\"alice\", \"bob\", \"charlie\"], address=\"local\")\n",
    "alice, bob, charlie = sf.PYU(\"alice\"), sf.PYU(\"bob\"), sf.PYU(\"charlie\")\n",
    "spu = sf.SPU(sf.utils.testing.cluster_def([\"alice\", \"bob\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b84680-6616-4d54-8582-bf753b71c01d",
   "metadata": {
    "execution": {},
    "libroFormatter": "formatter-string"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(dataset(\"creditcard\"), sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690bcd0d-cf05-41b5-8555-a921475839df",
   "metadata": {
    "execution": {},
    "libroFormatter": "formatter-string"
   },
   "outputs": [],
   "source": [
    "seed = 1234\n",
    "plt.rc(\"figure\", autolayout=True)\n",
    "plt.rc(\n",
    "    \"axes\",\n",
    "    labelweight=\"bold\",\n",
    "    labelsize=\"large\",\n",
    "    titleweight=\"bold\",\n",
    "    titlesize=14,\n",
    "    titlepad=10,\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3458da31-2cc2-4c78-b195-4c6e4b0dff24",
   "metadata": {
    "execution": {},
    "libroFormatter": "formatter-string"
   },
   "outputs": [],
   "source": [
    "df = df[~df.duplicated()]\n",
    "df.drop(\"Time\", axis=1, inplace=True)\n",
    "df[df.duplicated()][\"Class\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223c80e3-51f7-4913-8230-40d6b05f0ef4",
   "metadata": {
    "execution": {},
    "libroFormatter": "formatter-string"
   },
   "outputs": [],
   "source": [
    "df = df[~df.duplicated()]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2da4040-eecd-4e46-b072-eddf8b03eec1",
   "metadata": {
    "execution": {},
    "libroFormatter": "formatter-string"
   },
   "outputs": [],
   "source": [
    "df[\"Amount_bc\"] = boxcox1p(df[\"Amount\"], boxcox_normmax(df[\"Amount\"] + 1))\n",
    "df[\"Amount_log\"] = np.log(1 + df[\"Amount\"])\n",
    "df.drop([\"Amount\", \"Amount_log\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0e49c7-23d8-4c50-8082-0afb94304c30",
   "metadata": {
    "execution": {},
    "libroFormatter": "formatter-string"
   },
   "outputs": [],
   "source": [
    "count_of_ones = (df[\"Class\"] == 0).sum()\n",
    "\n",
    "print(count_of_ones)\n",
    "count_of_ones = (df[\"Class\"] == 1).sum()\n",
    "\n",
    "print(count_of_ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86025c1a-66b1-4f5e-92b8-a751dad0b7de",
   "metadata": {
    "execution": {},
    "libroFormatter": "formatter-string"
   },
   "outputs": [],
   "source": [
    "df[\"Class\"] = df[\"Class\"].astype(float)\n",
    "X = df.drop(\"Class\", axis=1)\n",
    "y = df.Class\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "pca = PCA()\n",
    "pca.fit_transform(X_scaled);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa46dc6-cd11-42a9-83e7-12356e023e23",
   "metadata": {
    "execution": {},
    "libroFormatter": "formatter-string"
   },
   "outputs": [],
   "source": [
    "cum_sum = np.cumsum(pca.explained_variance_ratio_) * 100\n",
    "comp = [n for n in range(len(cum_sum))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d10565-a4ff-446b-aab0-9a1e8fc0066a",
   "metadata": {
    "execution": {},
    "libroFormatter": "formatter-string"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 5))\n",
    "plt.plot(comp, cum_sum, marker=\".\")\n",
    "plt.xlabel(\"PCA Components\")\n",
    "plt.ylabel(\"Cumulative Explained Variance (%)\")\n",
    "plt.title(\"PCA\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0f4df6-f307-4fda-97d9-09c98dc9237b",
   "metadata": {
    "execution": {},
    "libroFormatter": "formatter-string"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=seed\n",
    ")\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, stratify=y_train, random_state=seed\n",
    ")\n",
    "print(f\"Training set: {X_train.shape[0]}\")\n",
    "print(f\"Validation set: {X_val.shape[0]}\")\n",
    "print(f\"Test set: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4649f297-2234-4859-94e7-e50aa187df02",
   "metadata": {
    "execution": {},
    "libroFormatter": "formatter-string"
   },
   "outputs": [],
   "source": [
    "# from secretflow.security.aggregation import SecureAggregator\n",
    "# from secretflow.ml.nn import FLModel\n",
    "# import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "# EPOCHS = 100\n",
    "# BATCH_SIZE = 256\n",
    "# def objective(input_shape,num_classes,name='model'):\n",
    "#     def objective(trial):\n",
    "\n",
    "#         model = keras.Sequential()\n",
    "\n",
    "#         in_feat = X_train.shape[0]\n",
    "\n",
    "#         for i in range(trial.suggest_int(\"n_layers\", 1, 2)):\n",
    "#             out_feat = trial.suggest_int(\"n_units_{}\".format(i+1), 1, 40)\n",
    "#             model.add(keras.layers.Dense(units=out_feat, activation='relu'))\n",
    "#             model.add(keras.layers.Dropout(trial.suggest_uniform(\"dropout_{}\".format(i+1), 0.2, 0.5)))\n",
    "#             in_feat=out_feat\n",
    " \n",
    "#         model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "#         model.compile(loss='binary_crossentropy',\n",
    "#                     optimizer=keras.optimizers.Adam(trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)),\n",
    "#                     metrics=['accuracy'])\n",
    "    \n",
    "#         early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", patience=5, restore_best_weights=True)\n",
    "    \n",
    "#         model.fit(X_train, y_train,\n",
    "#                 validation_data = (X_val, y_val),\n",
    "#                 shuffle = True,\n",
    "#                 batch_size = BATCH_SIZE,\n",
    "#                 epochs = EPOCHS,\n",
    "#                 callbacks = [early_stop], \n",
    "#                 verbose = False )\n",
    "    \n",
    "#         score = model.evaluate(X_val, y_val, verbose=0)\n",
    "                  \n",
    "#         return score[1]\n",
    "#     return objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680f7975-8780-4534-a82e-5d64856a0b9c",
   "metadata": {
    "execution": {},
    "libroFormatter": "formatter-string"
   },
   "outputs": [],
   "source": [
    "# import optuna\n",
    "# num_classes=10\n",
    "# input_shape=(28,28,1)\n",
    "# study = optuna.create_study(direction=\"maximize\")\n",
    "# study.optimize(objective(input_shape,num_classes), n_trials=10)\n",
    "\n",
    "# print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "# print(\"Best trial:\")\n",
    "# trial = study.best_trial\n",
    "\n",
    "# print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "# params_1 = []\n",
    "\n",
    "# for key, value in trial.params.items():\n",
    "#     params_1.append(value)\n",
    "#     print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa10066-c4d0-4156-aa87-4907e5c54895",
   "metadata": {
    "execution": {},
    "libroFormatter": "formatter-string"
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "X_val = X_val.reshape(X_val.shape[0], X_val.shape[1], 1)\n",
    "X_train.shape, X_test.shape, X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a49785-e9c4-4590-a9b1-1cada187c568",
   "metadata": {
    "execution": {},
    "libroFormatter": "formatter-string"
   },
   "outputs": [],
   "source": [
    "parts = {\n",
    "    alice: 0.5,\n",
    "    bob: 0.5,\n",
    "}\n",
    "if not isinstance(y_train, np.ndarray):\n",
    "    y_train = y_train.to_numpy()\n",
    "if not isinstance(y_test, np.ndarray):\n",
    "    y_test = y_test.to_numpy()\n",
    "if not isinstance(y_val, np.ndarray):\n",
    "    y_val = y_val.to_numpy()\n",
    "fed_train_x = create_ndarray(X_train, parts=parts, axis=0)\n",
    "fed_train_y = create_ndarray(y_train, parts=parts, axis=0)\n",
    "fed_val_x = create_ndarray(X_val, parts=parts, axis=0)\n",
    "fed_val_y = create_ndarray(y_val, parts=parts, axis=0)\n",
    "fed_test_x = create_ndarray(X_test, parts=parts, axis=0)\n",
    "fed_test_y = create_ndarray(y_test, parts=parts, axis=0)\n",
    "print(fed_train_x.partition_shape())\n",
    "print(fed_train_y.partition_shape())\n",
    "print(fed_val_x.partition_shape())\n",
    "print(fed_val_y.partition_shape())\n",
    "print(fed_test_x.partition_shape())\n",
    "print(fed_test_y.partition_shape())\n",
    "fed_train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7c24a8-07f1-429e-bc42-03abbd321cdf",
   "metadata": {
    "execution": {},
    "libroFormatter": "formatter-string"
   },
   "outputs": [],
   "source": [
    "def create_model(input_shape, num_classes, name=\"model\"):\n",
    "    def create_model():\n",
    "        from tensorflow.keras.layers import Flatten, Dense, Dropout, BatchNormalization\n",
    "        from tensorflow.keras.layers import Conv1D, MaxPool1D\n",
    "        from tensorflow.keras import Sequential\n",
    "        from tensorflow.keras.optimizers import Adam\n",
    "        \n",
    "        model = Sequential()\n",
    "        model.add(Conv1D(32, 2, activation=\"relu\", input_shape=input_shape))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.2))\n",
    "\n",
    "        model.add(Conv1D(64, 2, activation=\"relu\"))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(64, activation=\"relu\"))\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "        model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=Adam(lr=0.0001), loss=\"binary_crossentropy\", metrics=[\"accuracy\"]\n",
    "        )\n",
    "        model.summary()\n",
    "\n",
    "        return model\n",
    "\n",
    "    return create_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d0033e-c051-47f9-8993-87ca82609da3",
   "metadata": {
    "execution": {},
    "libroFormatter": "formatter-string"
   },
   "outputs": [],
   "source": [
    "\n",
    "device_list = [alice, bob]\n",
    "secure_aggregator = SecureAggregator(charlie, [alice, bob])\n",
    "spu_aggregator = SPUAggregator(spu)\n",
    "num_classes = 10\n",
    "input_shape = X_train[0].shape\n",
    "model = create_model(input_shape, num_classes)\n",
    "fed_model = FLModel(\n",
    "    server=charlie,\n",
    "    device_list=device_list,\n",
    "    model=model,\n",
    "    aggregator=secure_aggregator,\n",
    "    strategy=\"fed_avg_w\",\n",
    "    backend=\"tensorflow\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1906ec30-ccfe-4384-ae1c-c174799b72e4",
   "metadata": {
    "execution": {},
    "libroFormatter": "formatter-string"
   },
   "outputs": [],
   "source": [
    "X_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f1224e-1640-47a6-bc6d-1711e73999db",
   "metadata": {
    "execution": {},
    "libroFormatter": "formatter-string"
   },
   "outputs": [],
   "source": [
    "y_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4140029-859a-4104-a482-ff08ccd085bd",
   "metadata": {
    "execution": {},
    "libroFormatter": "formatter-string"
   },
   "outputs": [],
   "source": [
    "X_val.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6d3dba-d4db-4057-9dfb-33c22092601e",
   "metadata": {
    "execution": {},
    "libroFormatter": "formatter-string"
   },
   "outputs": [],
   "source": [
    "y_val.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a7ab61-44f5-45bb-8061-6b426a41c376",
   "metadata": {
    "execution": {},
    "libroFormatter": "formatter-string"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 5\n",
    "BATCH_SIZE = 256\n",
    "history = fed_model.fit(\n",
    "    fed_train_x,\n",
    "    fed_train_y,\n",
    "    validation_data=(fed_val_x, fed_val_y),\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    aggregate_freq=1,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9406ca-7347-4282-8f15-0617a889df9d",
   "metadata": {
    "execution": {},
    "libroFormatter": "formatter-string"
   },
   "outputs": [],
   "source": [
    "global_eval, local_eval = fed_model.evaluate(fed_test_x, fed_test_y)\n",
    "for e in global_eval:\n",
    "    print(e.name, e.result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fceb985-f199-4ff4-a537-022393e2633f",
   "metadata": {
    "execution": {},
    "libroFormatter": "formatter-string"
   },
   "outputs": [],
   "source": [
    "# Draw accuracy values for training & validation\n",
    "plt.plot(history[\"global_history\"]['accuracy'])\n",
    "plt.plot(history[\"global_history\"]['val_accuracy'])\n",
    "plt.title('FLModel accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Valid'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Draw loss for training & validation\n",
    "plt.plot(history[\"global_history\"]['loss'])\n",
    "plt.plot(history[\"global_history\"]['val_loss'])\n",
    "plt.title('FLModel loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Valid'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
