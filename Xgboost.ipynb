{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b4ee53-6745-447a-b8dc-81a559d9732c",
   "metadata": {
    "execution": {},
    "libroFormatter": "formatter-string"
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "from secretflow.utils.simulation.datasets import dataset\n",
    "from secretflow.stats.score_card import ScoreCard\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    roc_auc_score,\n",
    ")\n",
    "import seaborn as sns\n",
    "from secretflow.ml.boost.homo_boost import SFXgboost\n",
    "import tempfile\n",
    "import secretflow as sf\n",
    "from secretflow.data.horizontal import read_csv as h_read_csv\n",
    "from secretflow.security.aggregation import SecureAggregator\n",
    "from secretflow.security.compare import SPUComparator\n",
    "import time\n",
    "\n",
    "\n",
    "data_df = pd.read_csv(dataset(\"creditcard\"), sep=\",\")\n",
    "print(\n",
    "    \"Credit Card Fraud Detection data -  rows:\",\n",
    "    data_df.shape[0],\n",
    "    \" columns:\",\n",
    "    data_df.shape[1],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddc191c-160d-4fbc-83ce-64faf797dcf9",
   "metadata": {
    "libroCellType": "markdown",
    "libroFormatter": "formatter-string"
   },
   "source": [
    "# 数据探索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698d255c-1e22-4f10-b49a-0f5285aa6725",
   "metadata": {
    "execution": {},
    "libroFormatter": "formatter-string"
   },
   "outputs": [],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7adf0d2-749c-4d07-8eb2-b9784f875b9b",
   "metadata": {
    "execution": {},
    "libroFormatter": "formatter-string"
   },
   "outputs": [],
   "source": [
    "data_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809832aa-0431-4dc2-957b-49deaa6ab4c0",
   "metadata": {
    "execution": {},
    "libroFormatter": "formatter-string"
   },
   "outputs": [],
   "source": [
    "total = data_df.isnull().sum().sort_values(ascending=False)\n",
    "percent = (data_df.isnull().sum() / data_df.isnull().count() * 100).sort_values(\n",
    "    ascending=False\n",
    ")\n",
    "pd.concat([total, percent], axis=1, keys=[\"Total\", \"Percent\"]).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1c6fd2-4205-4dee-96ff-4e10ebfc58aa",
   "metadata": {
    "execution": {},
    "libroFormatter": "formatter-string"
   },
   "outputs": [],
   "source": [
    "temp = data_df[\"Class\"].value_counts()\n",
    "new_df = pd.DataFrame({\"Class\": temp.index, \"values\": temp.values})\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740df5e6-9cf8-4538-9e1c-ca25fac8a248",
   "metadata": {
    "execution": {},
    "libroFormatter": "formatter-string"
   },
   "outputs": [],
   "source": [
    "tmp = data_df[[\"Amount\", \"Class\"]].copy()\n",
    "class_0 = tmp.loc[tmp[\"Class\"] == 0][\"Amount\"]\n",
    "class_1 = tmp.loc[tmp[\"Class\"] == 1][\"Amount\"]\n",
    "class_0.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a287cb4b-f554-49eb-a06c-694ca632c686",
   "metadata": {
    "execution": {},
    "libroFormatter": "formatter-string"
   },
   "outputs": [],
   "source": [
    "class_1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc285b7-7cac-4463-b062-aa70e32c6ba6",
   "metadata": {
    "execution": {},
    "libroFormatter": "formatter-string"
   },
   "outputs": [],
   "source": [
    "sf_df = data_df.copy()\n",
    "sf_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f57a845-75d7-476f-9a82-d8ce0db1f0a7",
   "metadata": {
    "libroCellType": "markdown",
    "libroFormatter": "formatter-string"
   },
   "source": [
    "# 准备数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39e35e2-03e2-425d-9fa9-48c7ddd4b8cc",
   "metadata": {
    "execution": {},
    "libroFormatter": "formatter-string"
   },
   "outputs": [],
   "source": [
    "half = len(sf_df) // 2\n",
    "h_alice = sf_df.iloc[:half]\n",
    "h_bob = sf_df.iloc[half:]\n",
    "# Save to temorary files.\n",
    "_, h_alice_path = tempfile.mkstemp()\n",
    "_, h_bob_path = tempfile.mkstemp()\n",
    "h_alice.head(), h_bob.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f9ebd9-a5b5-4d8c-a7f1-0eb4610d0598",
   "metadata": {
    "execution": {},
    "libroFormatter": "formatter-string"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "atrain_df, atest_df = train_test_split(\n",
    "    h_alice, test_size=0.2, random_state=1234, shuffle=True\n",
    ")\n",
    "atrain_df, avalid_df = train_test_split(\n",
    "    atrain_df, test_size=0.2, random_state=1234, shuffle=True\n",
    ")\n",
    "avalid_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e7910b-5ea8-4573-96eb-c2a90f19a77d",
   "metadata": {
    "execution": {},
    "libroFormatter": "formatter-string"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "scaler = StandardScaler()\n",
    "df_a = atrain_df.apply(\n",
    "    lambda x: label_encoder.fit_transform(x) if x.dtype == \"O\" else x\n",
    ")\n",
    "trainup = pd.DataFrame(scaler.fit_transform(df_a), columns=df_a.columns)\n",
    "cov_matrix = abs(trainup.cov())\n",
    "plt.figure(figsize=(20, 20))\n",
    "sns.heatmap(cov_matrix, annot=True, cmap=\"Blues\", fmt=\".2f\", linewidths=0.5)\n",
    "plt.title(\"Covariance Matrix Heatmap a\")\n",
    "plt.show()\n",
    "\n",
    "df_g = data_df.apply(lambda x: label_encoder.fit_transform(x) if x.dtype == \"O\" else x)\n",
    "trainup = pd.DataFrame(scaler.fit_transform(df_g), columns=df_g.columns)\n",
    "cov_matrix = abs(trainup.cov())\n",
    "plt.figure(figsize=(20, 20))\n",
    "sns.heatmap(cov_matrix, annot=True, cmap=\"Blues\", fmt=\".2f\", linewidths=0.5)\n",
    "plt.title(\"Covariance Matrix Heatmap global\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.title(\"Credit Card Transactions features correlation plot (Pearson)\")\n",
    "corr = data_df.corr()\n",
    "sns.heatmap(\n",
    "    corr,\n",
    "    xticklabels=corr.columns,\n",
    "    yticklabels=corr.columns,\n",
    "    annot=True,\n",
    "    cmap=\"Greens\",\n",
    "    fmt=\".2f\",\n",
    "    linewidths=0.5,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70719082-53bf-45bd-b9ae-8e3540415ed0",
   "metadata": {
    "execution": {},
    "libroFormatter": "formatter-string"
   },
   "outputs": [],
   "source": [
    "btrain_df, btest_df = train_test_split(\n",
    "    h_bob, test_size=0.2, random_state=1234, shuffle=True\n",
    ")\n",
    "btrain_df, bvalid_df = train_test_split(\n",
    "    btrain_df, test_size=0.2, random_state=1234, shuffle=True\n",
    ")\n",
    "bvalid_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0092f433-d913-4eb0-a889-2ba5c51b549c",
   "metadata": {
    "execution": {},
    "libroFormatter": "formatter-string"
   },
   "outputs": [],
   "source": [
    "atrain_df.to_csv(h_alice_path, index=False)\n",
    "btrain_df.to_csv(h_bob_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21554f02-5d74-4525-b5a3-1befcb7b3f02",
   "metadata": {
    "libroCellType": "markdown",
    "libroFormatter": "formatter-string"
   },
   "source": [
    "# 单方模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc927492-fad1-4860-9e00-c9caf5d76c10",
   "metadata": {
    "execution": {},
    "libroFormatter": "formatter-string"
   },
   "outputs": [],
   "source": [
    "target = \"Class\"\n",
    "predictors = [\n",
    "    \"Time\",\n",
    "    \"V1\",\n",
    "    \"V2\",\n",
    "    \"V3\",\n",
    "    \"V4\",\n",
    "    \"V5\",\n",
    "    \"V6\",\n",
    "    \"V7\",\n",
    "    \"V8\",\n",
    "    \"V9\",\n",
    "    \"V10\",\n",
    "    \"V11\",\n",
    "    \"V12\",\n",
    "    \"V13\",\n",
    "    \"V14\",\n",
    "    \"V15\",\n",
    "    \"V16\",\n",
    "    \"V17\",\n",
    "    \"V18\",\n",
    "    \"V19\",\n",
    "    \"V20\",\n",
    "    \"V21\",\n",
    "    \"V22\",\n",
    "    \"V23\",\n",
    "    \"V24\",\n",
    "    \"V25\",\n",
    "    \"V26\",\n",
    "    \"V27\",\n",
    "    \"V28\",\n",
    "    \"Amount\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6a5114-41a1-4c18-9c72-4946802363b9",
   "metadata": {
    "execution": {},
    "libroFormatter": "formatter-string"
   },
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(atrain_df[predictors], atrain_df[target].values)\n",
    "dvalid = xgb.DMatrix(avalid_df[predictors], avalid_df[target].values)\n",
    "dtest = xgb.DMatrix(atest_df[predictors], atest_df[target].values)\n",
    "watchlist = [(dtrain, \"train\"), (dvalid, \"valid\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cece93c6-4465-4cf8-a2ec-4d192a3422f7",
   "metadata": {
    "execution": {},
    "libroFormatter": "formatter-string"
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    # XGBoost parameter tutorial\n",
    "    # https://xgboost.readthedocs.io/en/latest/parameter.html\n",
    "    \"max_depth\": 6,  # max depth\n",
    "    \"eta\": 0.3,  # learning rate\n",
    "    \"objective\": \"binary:logistic\",  # objection function，support \"binary:logistic\",\"reg:logistic\",\"multi:softmax\",\"multi:softprob\",\"reg:squarederror\"\n",
    "    \"max_bin\": 64,  # Max num of binning\n",
    "    \"subsample\": 0.8,  # Subsample rate by rows\n",
    "    \"colsample_bytree\": 0.9,  # Feature selection rate by tree\n",
    "    \"eval_metric\": \"auc\",\n",
    "}\n",
    "num_round = 20\n",
    "model = xgb.train(params, dtrain, num_round, evals=watchlist, early_stopping_rounds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b914e5e3-7385-4555-be25-155cac96bd3f",
   "metadata": {
    "execution": {},
    "libroFormatter": "formatter-string"
   },
   "outputs": [],
   "source": [
    "preds =model.predict(dtest)\n",
    "y_pred_prob = preds  # 获得预测的概率\n",
    "y_pred = np.where(y_pred_prob > 0.5, 1, 0)  # 根据阈值将概率转换为标签\n",
    "\n",
    "# Step 2: 生成混淆矩阵\n",
    "cm = confusion_matrix(atest_df[target].values , y_pred)\n",
    "\n",
    "# Step 3: 可视化混淆矩阵\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Class 0', 'Class 1'],\n",
    "            yticklabels=['Class 0', 'Class 1'])\n",
    "plt.ylabel('actual')\n",
    "plt.xlabel('predict')\n",
    "plt.title('confuse matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666ece32-b835-4618-87e2-02062c9382b3",
   "metadata": {
    "execution": {},
    "libroFormatter": "formatter-string"
   },
   "outputs": [],
   "source": [
    "fig, (ax) = plt.subplots(ncols=1, figsize=(8, 5))\n",
    "xgb.plot_importance(\n",
    "    model, height=0.8, title=\"Features importance (XGBoost)\", ax=ax, color=\"green\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1573c4-e93a-47e3-8d3e-efcce0f828e0",
   "metadata": {
    "libroCellType": "markdown",
    "libroFormatter": "formatter-string"
   },
   "source": [
    "# 准备多方"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84568e09-f248-41af-be5b-ee28a12174ad",
   "metadata": {
    "execution": {},
    "libroFormatter": "formatter-string"
   },
   "outputs": [],
   "source": [
    "# Check the version of your SecretFlow\n",
    "print(\"The version of SecretFlow: {}\".format(sf.__version__))\n",
    "\n",
    "# In case you have a running secretflow runtime already.\n",
    "sf.shutdown()\n",
    "\n",
    "sf.init([\"alice\", \"bob\", \"charlie\"], address=\"local\")\n",
    "alice, bob, charlie = sf.PYU(\"alice\"), sf.PYU(\"bob\"), sf.PYU(\"charlie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2c31db-7f4a-4f87-9965-b7f9ca82f571",
   "metadata": {
    "execution": {},
    "libroFormatter": "formatter-string"
   },
   "outputs": [],
   "source": [
    "aggr = SecureAggregator(device=charlie, participants=[alice, bob])\n",
    "\n",
    "spu = sf.SPU(sf.utils.testing.cluster_def(parties=[\"alice\", \"bob\"]))\n",
    "comp = SPUComparator(spu)\n",
    "hdf = h_read_csv(\n",
    "    {alice: h_alice_path, bob: h_bob_path},\n",
    "    aggregator=aggr,\n",
    "    comparator=comp,\n",
    ")\n",
    "hdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e9e1aa-3ed5-4c34-8ae2-b883fc5b66cb",
   "metadata": {
    "execution": {},
    "libroFormatter": "formatter-string"
   },
   "outputs": [],
   "source": [
    "hdf.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63144005-8ae1-490d-90e8-e94086ac9691",
   "metadata": {
    "libroCellType": "markdown",
    "libroFormatter": "formatter-string"
   },
   "source": [
    "# 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d84105-a6a6-4bcd-9453-ffeabf5b88ed",
   "metadata": {
    "execution": {},
    "libroFormatter": "formatter-string"
   },
   "outputs": [],
   "source": [
    "print('Horizontal df:\\n', hdf.min())\n",
    "print('Horizontal df:\\n', hdf.max())\n",
    "print('Horizontal df:\\n', hdf.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adf6a8d-9379-4aeb-b7bd-1fa5c72c0664",
   "metadata": {
    "execution": {},
    "libroFormatter": "formatter-string"
   },
   "outputs": [],
   "source": [
    "from secretflow.preprocessing import StandardScaler,MinMaxScaler\n",
    "scaler_min = MinMaxScaler()\n",
    "scaler_std = StandardScaler()\n",
    "\n",
    "scaled_time = scaler_min.fit_transform(hdf['Time'])\n",
    "hdf['Time']=scaled_time\n",
    "scaled_time = scaler_std.fit_transform(hdf['Time'])\n",
    "hdf['Time']=scaled_time\n",
    "\n",
    "print('Min: ', hdf['Time'].min())\n",
    "print('Max: ', hdf['Time'].max())\n",
    "\n",
    "scaled_amount = scaler_std.fit_transform(hdf['Amount'])\n",
    "hdf['Amount']=scaled_amount\n",
    "\n",
    "print('Min: ', hdf['Amount'].min())\n",
    "print('Max: ', hdf['Amount'].max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3af157-713c-41de-8d8f-937aa06d341d",
   "metadata": {
    "execution": {},
    "libroFormatter": "formatter-string"
   },
   "outputs": [],
   "source": [
    "bst = SFXgboost(server=charlie, clients=[alice, bob])\n",
    "params = {\n",
    "    \"max_depth\": 6,  # max depth\n",
    "    \"eta\": 0.3,  # learning rate\n",
    "    \"objective\": \"binary:logistic\",  # objection function，support \"binary:logistic\",\"reg:logistic\",\"multi:softmax\",\"multi:softprob\",\"reg:squarederror\"\n",
    "    \"max_bin\": 64,  # Max num of binning\n",
    "    \"subsample\": 0.8,  # Subsample rate by rows\n",
    "    \"colsample_bytree\": 0.9,  # Feature selection rate by tree\n",
    "    \"eval_metric\": \"auc\",  # supported eval metric：\n",
    "    \"hess_key\": \"hess\",  # Required, Mark hess columns, optionally choosing a column name that is not in the data set\n",
    "    \"grad_key\": \"grad\",  # Required，Mark grad columns, optionally choosing a column name that is not in the data set\n",
    "    \"label_key\": \"Class\",  # Required，ark label columns, optionally choosing a column name that is not in the data set\n",
    "}\n",
    "start = time.time()\n",
    "modelsf = bst.train(hdf, hdf, params=params, num_boost_round=20)\n",
    "print(f\"train time: {time.time() - start}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d96f37-aa15-4a54-8bbd-1d32e9c9ac5b",
   "metadata": {
    "libroCellType": "markdown",
    "libroFormatter": "formatter-string"
   },
   "source": [
    "# 评估模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eca34e2-e2d0-4b93-88e1-5673f2e7a77b",
   "metadata": {
    "execution": {},
    "libroFormatter": "formatter-string"
   },
   "outputs": [],
   "source": [
    "model_path = {\n",
    "    alice: \"./test_alice.json\",\n",
    "    bob: \"./test_bob.json\",\n",
    "}\n",
    "bst.save_model(model_path)\n",
    "result = bst.eval(model_path=model_path, hdata=hdf, params=params)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6f1a54-4567-4529-a5d8-deda2caa3ea9",
   "metadata": {
    "execution": {},
    "libroFormatter": "formatter-string"
   },
   "outputs": [],
   "source": [
    "model_sf = xgb.Booster()  # 初始化一个Booster对象\n",
    "model_sf.load_model(\"test_alice.json\")  # 从JSON文件加载模型\n",
    "temp_data = atest_df.copy()\n",
    "x = temp_data.drop(columns=\"Class\")\n",
    "y = temp_data[\"Class\"]\n",
    "print(x.head())\n",
    "print(y.head())\n",
    "matrix = xgb.DMatrix(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea11e598-2888-4b35-93d0-bf96aa7f9c0a",
   "metadata": {
    "execution": {},
    "libroFormatter": "formatter-string"
   },
   "outputs": [],
   "source": [
    "predictions = model_sf.predict(matrix)\n",
    "print(predictions)\n",
    "sf_prediction = predictions  # 获得预测的概率\n",
    "sf_proc_pred = np.where(sf_prediction > 0.5, 1, 0)  # 根据阈值将概率转换为标签\n",
    "print(confusion_matrix(y.values, sf_proc_pred))\n",
    "sf_cm = confusion_matrix(y.values, sf_proc_pred)\n",
    "\n",
    "# 可视\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(\n",
    "    sf_cm,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=[\"Class 0\", \"Class 1\"],\n",
    "    yticklabels=[\"Class 0\", \"Class 1\"],\n",
    ")\n",
    "plt.ylabel(\"actual\")\n",
    "plt.xlabel(\"predict\")\n",
    "plt.title(\"confuse matrix\")\n",
    "plt.show()\n",
    "\n",
    "print(classification_report(y.values, sf_proc_pred))\n",
    "\n",
    "fig, (ax) = plt.subplots(ncols=1, figsize=(8, 5))\n",
    "xgb.plot_importance(\n",
    "    model_sf, height=0.8, title=\"Features importance (XGBoost)\", ax=ax, color=\"green\"\n",
    ")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
